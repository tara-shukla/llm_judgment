{"cells":[{"cell_type":"markdown","metadata":{"id":"SZOjBvjWsaF3"},"source":["##Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87480,"status":"ok","timestamp":1733683714892,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"},"user_tz":300},"id":"lNudF_5CmewF","outputId":"5577c746-9aca-414c-b3ad-3a51f21c909a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#connect to drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":15622,"status":"ok","timestamp":1733683730512,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"},"user_tz":300},"id":"ZFT6hj3fpdcv","outputId":"e981d938-0a7c-469f-d825-84e5ef025525"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n","Collecting transformers\n","  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Collecting tokenizers<0.22,>=0.21 (from transformers)\n","  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.20.3\n","    Uninstalling tokenizers-0.20.3:\n","      Successfully uninstalled tokenizers-0.20.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.46.3\n","    Uninstalling transformers-4.46.3:\n","      Successfully uninstalled transformers-4.46.3\n","Successfully installed tokenizers-0.21.0 transformers-4.47.0\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}],"source":["!pip install -U transformers\n","#!pip install vllm==0.5.3.post1\n","!pip install -U torch\n","!pip install pandas"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"kjCeuRpRmpdZ","executionInfo":{"status":"ok","timestamp":1733683741773,"user_tz":300,"elapsed":11264,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"outputs":[],"source":["\n","#get data file\n","!wget -q -O data.csv \"https://docs.google.com/uc?export=download&id=1mFCRDIWsokNF02WBk77m0CIE7ZfRBp_k\""]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":952,"status":"ok","timestamp":1733683742723,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"},"user_tz":300},"id":"zJSNmt0KmrVM","outputId":"77ed1682-2ea1-4b7e-a60f-85255be3c64e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['text_id_kaggle', 'full_text', 'gender', 'grade', 'race_ethnicity',\n","       'num_words', 'num_words2', 'num_words3', 'num_sent', 'num_para',\n","       'num_word_div_para', 'MTLD', 'TTR', 'Type', 'Token', 'task', 'SES',\n","       'prompt', 'Overall', 'Cohesion', 'Syntax', 'Vocabulary', 'Phraseology',\n","       'Grammar', 'Conventions'],\n","      dtype='object')\n"]}],"source":["import pandas as pd\n","\n","data = pd.read_csv(\"data.csv\")\n","#print(data.head())\n","print(data.columns)"]},{"cell_type":"code","source":["df = data.sample(n=300, random_state=42)\n","print(df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lBN6wLQhBrsj","executionInfo":{"status":"ok","timestamp":1733683742723,"user_tz":300,"elapsed":6,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}},"outputId":"d9585c78-3494-4aad-cdde-817256816559"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['text_id_kaggle', 'full_text', 'gender', 'grade', 'race_ethnicity',\n","       'num_words', 'num_words2', 'num_words3', 'num_sent', 'num_para',\n","       'num_word_div_para', 'MTLD', 'TTR', 'Type', 'Token', 'task', 'SES',\n","       'prompt', 'Overall', 'Cohesion', 'Syntax', 'Vocabulary', 'Phraseology',\n","       'Grammar', 'Conventions'],\n","      dtype='object')\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ITagMyjLkVQO","executionInfo":{"status":"ok","timestamp":1733683742723,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"outputs":[],"source":["# prompt= ''' Please read the following essay and evaluate it according to the provided rubric. Assign a score from 1 to 5 in each category based on the specified criteria. Output the scores as a JSON object in the following format:\n","# {\n","#   \"overall\": score,\n","#   \"cohesion\": score\n","#   \"syntax\": score,\n","#   \"vocabulary\": score,\n","#   \"phraseology\": score,\n","#   \"grammar\": score,\n","#   \"conventions\": score,\n","# }\n","\n","# Each score should be an integer between 1 and 5: use the following rubric for scoring:\n","# Key Terms and Definitions\n","# Phrase: Multiple word units\n","# Grammar: The rules by which words change their forms, including the use of word classes and grammatical morphology in English. Word  classes include prepositions, pronouns, nouns, verbs, etc… Grammatical morphology includes third person, plural, possessive, etc…\n","# Syntax: Structuring sentences according to syntactic rules related to coordinating clauses, developing syntactic phrases (noun, verb,  preposition phrases), phrasal and clausal dependency, and transformations such as passives, relative clauses, and negations.\n","# Cohesive device: Cohesive devices are used as links between two or more items (e.g., words, phrases, clauses) in a text to enhance text  cohesion. These include the use of conjunctions (and, but, if, on the other hand), transitions (first, next, finally, for example), repetition of  words, phrases, and ideas across sentences and paragraphs, and the use of anaphor (pronouns replacing nouns).\n","# Simple, complex, and compound sentences\n","#  -Simple: Independent clause\n","#  -Complex: Independent and dependent clauses\n","#  -Compound: Two of more independent clauses\n","# Chunks: Multiple words that combine to have a single meaning. Often memorized without knowing what the individual words mean (e.g., “How are you” for “Hello”)\n","# Lexical bundles: Multiple word units that are common in English but are not idiomatic (“There is”). More common than collocations Collocations: Two or more words that are often used together (e.g., save time, go to bed, fast food)\n","# Idioms: multi-word unit where meaning not deducible from those of the individual words (kick the bucket, rain cats and dogs)\n","\n","# Overall\n","# Score 5: Native-like facility in the use of language with syntactic variety, appropriate word choice and phrases; well-controlled text organization; precise use of grammar and conventions; rare language inaccuracies that do not impede communication.\n","# Score 4: Facility in the use of language with syntactic variety and range of words and phrases; controlled organization; accuracy in grammar and conventions; occasional language inaccuracies that rarely impede communication.\n","# Score 3: Facility limited to the use of common structures and generic vocabulary; organization generally controlled although connection sometimes absent or unsuccessful; errors in grammar and syntax and usage. Communication is impeded by language inaccuracies in some cases.\n","# Score 2: Inconsistent facility in sentence formation, word choice, and mechanics; organization partially developed but may be missing or unsuccessful. Communication impeded in many instances by language inaccuracies.\n","# Score 1: A limited range of familiar words or phrases loosely strung together; frequent errors in grammar (including syntax) and usage. Communication impeded in most cases by language inaccuracies.\n","# Cohesion\n","# Score 5: Text organization consistently well-controlled using a variety of effective linguistic features such as reference and transitional words and phrases to connect ideas across sentences and paragraphs; appropriate overlap of ideas.\n","# Score 4: Organization generally well-controlled; a range of cohesive devices used appropriately such as reference and transitional words and phrases to connect ideas; generally appropriate overlap of ideas\n","# Score 3: Organization generally controlled; cohesive devices used but limited in type; some repetitive, mechanical, or faulty use of cohesion use within and/or between sentences and paragraphs.\n","# Score 2: Organization only partially developed with a lack of logical sequencing of ideas; some basic cohesive devices used but with inaccuracy or repetition.\n","# Score 1: No clear control of organization; cohesive devices not present or unsuccessfully used; presentation of ideas unclear.\n","# Syntax\n","# Score 5: Flexible and effective use of a full range of syntactic structures including simple, compound, and complex sentences; there may be rare minor and negligible errors in sentence formation.\n","# Score 4: Appropriate use of a variety of syntactic structures, such as simple, compound, and complex sentences; occasional errors or inappropriateness in sentence formation.\n","# Score 3: Simple, compound, and complex syntactic structures present although the range may be limited; some apparent errors in sentence formation, especially in more complex sentences.\n","# Score 2: Some sentence variation used; many sentence structure problems.\n","# Score 1: Pervasive and basic errors in sentence structure and word order that cause confusion; basic sentence errors are common.\n","# Vocabulary\n","# Score 5: Wide range of vocabulary flexibly and effectively used to convey precise meanings; skillful use of topic-related terms and less common words; rare negligible inaccuracies in word use.\n","# Score 4: Sufficient range of vocabulary to allow flexibility and precision; appropriate use of topic-related terms and less common lexical items\n","# Score 3: Minimally adequate range of vocabulary for the topic; no precise use of subtle word meanings; topic-related terms only used occasionally; attempts to use less common vocabulary but with some inaccuracy\n","# Score 2: Narrow range of vocabulary to convey basic and elementary meaning; topic-related terms used inappropriately; errors in word formation and word choice that may distort meanings\n","# Score 1: Limited vocabulary often inappropriately used; limited control of word choice and word forms; little attempt to use topic-related terms\n","# Phraseology\n","# Score 5: Flexible and effective use of a variety of phrases, such as idioms, collocations, and lexical bundles, to convey precise and subtle meanings; rare minor inaccuracies that are negligible.\n","# Score 4: Appropriate use of a variety of phrases, such as idioms, collocations, and lexical bundles; occasional inaccuracies and colloquialisms.\n","# Score 3: Evident use of phrases such as idioms, collocations, and lexical bundles but without much variety; some noticeable repetitions and misuses.\n","# Score 2: Narrow range of phrases, such as collocations and lexical bundles, used to convey basic and elementary meaning; many repetitions and/or misuses of phrases.\n","# Score 1: Memorized chunks of language, or simple phrasal patterns, predominate; many repetitions and misuses of phrases.\n","# Grammar\n","# Score 5: Command of grammar and usage with few or no errors.\n","# Score 4: Minimal errors in grammar and usage.\n","# Score 3: Some errors in grammar and usage.\n","# Score 2: Many errors in grammar and usage.\n","# Score 1: Errors in grammar and usage throughout.\n","# Conventions\n","# Score 5: Consistent use of appropriate conventions to convey meaning; spelling, capitalization, and punctuation errors nonexistent or negligible.\n","# Score 4: Generally consistent use of appropriate conventions to convey meaning; spelling, capitalization, and punctuation errors few and not distracting.\n","# Score 3: Developing use of conventions to convey meaning; errors in spelling, capitalization, and punctuation that are sometimes distracting.\n","# Score 2: Variable use of conventions; spelling, capitalization, and punctuation errors frequent and distracting.\n","# Score 1: Minimal use of conventions; spelling, capitalization, and punctuation errors throughout.\n","# Here is the essay:\n","# '''"]},{"cell_type":"code","source":["#concat prompt\n","rubric= '''\n","Outputs each score as an integer between 1 and 5: use the following rubric for scoring:\n","\n","# Overall\n","# 5: Native-like facility in the use of language with syntactic variety, appropriate word choice and phrases; well-controlled text organization; precise use of grammar and conventions; rare language inaccuracies that do not impede communication.\n","# 1: A limited range of familiar words or phrases loosely strung together; frequent errors in grammar (including syntax) and usage. Communication impeded in most cases by language inaccuracies.\n","# Cohesion\n","# 5: Text organization consistently well-controlled using a variety of effective linguistic features such as reference and transitional words and phrases to connect ideas across sentences and paragraphs; appropriate overlap of ideas.\n","# 1: No clear control of organization; cohesive devices not present or unsuccessfully used; presentation of ideas unclear.\n","# Syntax\n","# 5: Flexible and effective use of a full range of syntactic structures including simple, compound, and complex sentences; there may be rare minor and negligible errors in sentence formation.\n","# 1: Pervasive and basic errors in sentence structure and word order that cause confusion; basic sentence errors are common.\n","# Vocabulary\n","# 5: Wide range of vocabulary flexibly and effectively used to convey precise meanings; skillful use of topic-related terms and less common words; rare negligible inaccuracies in word use.\n","# 1: Limited vocabulary often inappropriately used; limited control of word choice and word forms; little attempt to use topic-related terms\n","# Phraseology\n","# 5: Flexible and effective use of a variety of phrases, such as idioms, collocations, and lexical bundles, to convey precise and subtle meanings; rare minor inaccuracies that are negligible.\n","# 1: Memorized chunks of language, or simple phrasal patterns, predominate; many repetitions and misuses of phrases.\n","# Grammar\n","# 5: Command of grammar and usage with few or no errors.\n","# 1: Errors in grammar and usage throughout.\n","# Conventions\n","# 5: Consistent use of appropriate conventions to convey meaning; spelling, capitalization, and punctuation errors nonexistent or negligible.\n","# 1: Minimal use of conventions; spelling, capitalization, and punctuation errors throughout.\n","# Here is the essay:\n","'''"],"metadata":{"id":"-t36v8AxDPLa","executionInfo":{"status":"ok","timestamp":1733683742723,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"id":"c5o4UQsXhrmi","executionInfo":{"status":"ok","timestamp":1733683746479,"user_tz":300,"elapsed":3759,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}},"outputId":"704588b2-6d4e-45e7-d444-96b25508d714","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","from datasets import load_dataset\n","from torch.utils.data import DataLoader\n","from torch import cuda, tensor, no_grad\n","import torch\n","from tqdm.auto import tqdm\n","import json\n","from datasets import Dataset\n"],"metadata":{"id":"ISBTzIwhj6B5","executionInfo":{"status":"ok","timestamp":1733683760145,"user_tz":300,"elapsed":13671,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def preprocess(data):\n","    batch = {}\n","    batch['messages'] = [f\"Based on the following rubric:\\n'{rubric}'\\nAnd the following prompt:\\n'{prompt}'\\nThe essay:\\n'{full_text}'.\\ndeserves what score? Output the scores as a JSON object in the following format:{{'overall': score,'cohesion': score,'syntax': score,'vocabulary': score,'phraseology': score,'grammar': score,'conventions': score}}. I like to eat \" for full_text, prompt in zip(data['full_text'], data['prompt'])]\n","    #batch['labels'] = data['holistic_essay_score']\n","    batch['essay_ids'] = data['text_id_kaggle']\n","    return batch\n","\n","def compute_metric():\n","    return\n","\n","def collate(data):\n","    return {'messages': [ex['messages'] for ex in data],\n","            'essay_ids': [ex['essay_ids'] for ex in data]}\n","\n","batch_size = 1\n","print('loading dataset...\\n')\n","train_data = Dataset.from_pandas(df)\n","train_data = train_data.select_columns(['full_text', 'text_id_kaggle', 'prompt'])\n","train_data = train_data.map(preprocess, batched=True, batch_size=batch_size)\n","train_dataloader = DataLoader(train_data,\n","                               batch_size=batch_size, shuffle=False,\n","                               collate_fn=collate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["54064c3b040d420b915da7609936cd58","d4aa3f6acd6549779c5c81d4e4818dcb","83e05cda0102478f8eec6ebfd2f18cab","2e95f98365e04b04b1323512bff67d33","5e18abd6f7de4f64b5f595322a1fd27c","b47678ce1dc84c2a9dea9edfd8966f7c","c03b6eb041a24e0abb4fb10bec72dca0","7d5f8f6f494f4ecabd9f962ae63ba280","8b8153a80b464d508e84fa1e62a2d89f","bd0d4667c0e4425ead561288139425e3","a3a5f7f6649c4ebebcecbfcf2f515824"]},"id":"DCxBHm_flSiX","executionInfo":{"status":"ok","timestamp":1733685822989,"user_tz":300,"elapsed":1039,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}},"outputId":"d0d53219-9354-4ac4-ef61-88ad151cc647"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["loading dataset...\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/300 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54064c3b040d420b915da7609936cd58"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"Iz3Gl3Y2sfRm"},"source":["##LLM grading"]},{"cell_type":"code","source":["access_token = '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'\n","\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","pipe = pipeline(\n","    \"text-generation\",\n","    model=\"meta-llama/Llama-3.2-1B\",\n","    torch_dtype=torch.bfloat16,\n","    device_map=\"auto\",\n","    token = access_token,\n","    return_full_text=False,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"EkGGFYMks_Lj","executionInfo":{"status":"ok","timestamp":1733685781540,"user_tz":300,"elapsed":3275,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}},"outputId":"f4c871b3-c280-4a1f-8ef1-3809131b7525"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]}]},{"cell_type":"code","source":["epochs = 1\n","\n","num_training_steps = epochs * len(train_dataloader)\n","progress_bar = tqdm(range(num_training_steps))\n","\n","with open ('/content/drive/MyDrive/senior_thesis/outputs/llama_raw.csv', 'w') as out_file:\n","    out_file.write('essay_id,pred\\n')\n","    with no_grad():\n","        for _ in range(epochs):\n","            for i, batch in enumerate(train_dataloader):\n","                essay_ids = batch['essay_ids']\n","                for i in range(len(batch['messages'])):\n","                    out = pipe(batch['messages'], max_new_tokens=128, pad_token_id=pipe.tokenizer.eos_token_id)\n","                    out_file.write(f'{essay_ids[i]},\"{out[i][0][\"generated_text\"]}\"\\n')\n","                    print(f'{essay_ids[i]},\"{out[i][0][\"generated_text\"]}\"')\n","                progress_bar.update()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542,"referenced_widgets":["d355fa8214dc4c9da9053aadb8b294a7","45e79fd134c64d9d9813943f2e0e29cf","8b40d03085cb44769d6bdb90bf92a69d","cb445220a1a945ed85cf4edbfbae2456","639c940a7a494023bdea60ad15cfbd54","52fc3747877a4e3c8784b94462284d0d","6c06bbbf20d74b95ab78229dc72467df","aa056e410c7543e59c7f3b82385d137c","f37e0d9eb86340bfb7eeee209dbda42a","732c067679304d638654e2edf84d5e76","b7ee1349daf84e4a8c4366d8086961d7"]},"id":"wNYUmXp7lWVl","outputId":"b82c6cc5-6a4a-4945-acbb-0e2701ed458c","executionInfo":{"status":"error","timestamp":1733685834902,"user_tz":300,"elapsed":9551,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d355fa8214dc4c9da9053aadb8b294a7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["9CDD8FC77D5A,\"2 things that I love. I like to eat food that I like to eat and I like to eat food that I don't like. I like to eat food that I like to eat and I like to eat food that I don't like. I like to eat food that I like to eat and I like to eat food that I don't like. I like to eat food that I like to eat and I like to eat food that I don't like. I like to eat food that I like to eat and I like to eat food that I don't like. I like to eat food that I like to eat and I\"\n","C19EDCF7BDD6,\"1-5: 1: Native-like facility in the use of language with syntactic variety, appropriate word choice and phrases; well-controlled text organization; precise use of grammar and conventions; rare language inaccuracies that do not impede communication. 5: Native-like facility in the use of language with syntactic variety, appropriate word choice and phrases; well-controlled text organization; precise use of grammar and conventions; rare language inaccuracies that do not impede communication. 1: Native-like facility in the use of language with syntactic variety, appropriate word choice and phrases; well-controlled text organization; precise use of grammar and conventions;\"\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-98d97a51c09d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0messay_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'essay_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'messages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'messages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0mout_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{essay_ids[i]},\"{out[i][0][\"generated_text\"]}\"\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{essay_ids[i]},\"{out[i][0][\"generated_text\"]}\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     def preprocess(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1280\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m                 )\n\u001b[0;32m-> 1282\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1206\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generation_config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2253\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3239\u001b[0m         \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3240\u001b[0;31m         while self._has_unfinished_sequences(\n\u001b[0m\u001b[1;32m   3241\u001b[0m             \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3242\u001b[0m         ):\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_has_unfinished_sequences\u001b[0;34m(self, this_peer_finished, synced_gpus, device, cur_len, max_length)\u001b[0m\n\u001b[1;32m   2448\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mthis_peer_finished_flag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2451\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Be_AcEk4wH1S","executionInfo":{"status":"aborted","timestamp":1733684175866,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XozdOpGHrxl5","executionInfo":{"status":"aborted","timestamp":1733684175866,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"outputs":[],"source":["prompted_essays = [prompt + essay for essay in essays]"]},{"cell_type":"code","source":["prompted_essays[0]"],"metadata":{"id":"bTgUmb8ZC_ho","executionInfo":{"status":"aborted","timestamp":1733684175866,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tqdm"],"metadata":{"id":"mAMuE9DYAKuR","executionInfo":{"status":"aborted","timestamp":1733684175866,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U2opvbMEIX9R","executionInfo":{"status":"aborted","timestamp":1733684175866,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","from tqdm import tqdm\n","import time\n","from datetime import timedelta\n","\n","access_token = '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'\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\", token = access_token)\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"meta-llama/Llama-3.2-1B\",\n","    device_map=\"auto\",\n","    torch_dtype=torch.bfloat16,\n","    token = access_token\n",")\n","\n","llama_output = []\n","\n","def grade(prompt):\n","  messages = [{\"role\": \"user\", \"content\": prompt}]\n","  inputs = tokenizer(\n","        prompt,\n","        return_tensors=\"pt\",\n","        #truncation=True,\n","        #max_length=256\n","    ).to(model.device)\n","  outputs = model.generate(**inputs, max_new_tokens=256,pad_token_id=tokenizer.eos_token_id)\n","  generated_text = tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[1]:], skip_special_tokens=True)[0]\n","  return (generated_text.strip())\n"]},{"cell_type":"code","source":["grade(prompted_essays[0])"],"metadata":{"id":"bvCIZFmscbm2","executionInfo":{"status":"aborted","timestamp":1733684175867,"user_tz":300,"elapsed":4,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for essay in tqdm(prompted_essays, desc=\"Grading essays\", unit=\"essay\", mininterval=1.0):\n","    llama_output.append(grade(essay))"],"metadata":{"id":"WTywd4i2AgAI","executionInfo":{"status":"aborted","timestamp":1733684175867,"user_tz":300,"elapsed":4,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"collapsed":true,"id":"jUjpVsMWi5MB","executionInfo":{"status":"aborted","timestamp":1733684175867,"user_tz":300,"elapsed":4,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7bMZi7-aY49D","executionInfo":{"status":"aborted","timestamp":1733684175867,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import numpy as np\n","# import csv\n","# llama = np.array(llama_output)\n","\n","# if llama.ndim == 1:\n","#     llama = llama.reshape(-1, 1)\n","\n","# with open('/content/drive/MyDrive/senior_thesis/outputs/llama_raw_output.csv', 'w', newline='') as f:\n","#     writer = csv.writer(f)\n","#     writer.writerows(llama)"],"metadata":{"id":"GstyK-q9VIRj","executionInfo":{"status":"aborted","timestamp":1733684175867,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eACxlMjYJBbv","executionInfo":{"status":"aborted","timestamp":1733684175867,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"outputs":[],"source":["# json_data = llama_output[0]\n","\n","# gemma_df = pd.DataFrame(columns=[\"Overall\", \"Cohesion\", \"Syntax\", \"Vocabulary\", \"Phraseology\", \"Grammar\", \"Conventions\"])\n","# gemma_df = gemma_df.append(json_data, ignore_index=True)\n","\n","# gemma_df\n","# # def parse_llm_grades(output):\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iaQxpYVrLeu8","executionInfo":{"status":"aborted","timestamp":1733684175867,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"fB7qU6qFLn-o"},"source":["##IRT/GRM analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wIbw0hjfLrnr","executionInfo":{"status":"aborted","timestamp":1733684175867,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"outputs":[],"source":["!pip install pyirt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VcZGF3alLt9s","executionInfo":{"status":"aborted","timestamp":1733684175867,"user_tz":300,"elapsed":3,"user":{"displayName":"Tara Shukla","userId":"07348115335417162528"}}},"outputs":[],"source":["import pyirt\n","from pyirt import irt\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1aKuWsxK7_IZWrHTEAVCDQDqrQB7j8z4I","timestamp":1733683527257},{"file_id":"11nPsS3qqKI2zKGGcNr5JriTFUsokMXfx","timestamp":1733607877913}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"54064c3b040d420b915da7609936cd58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4aa3f6acd6549779c5c81d4e4818dcb","IPY_MODEL_83e05cda0102478f8eec6ebfd2f18cab","IPY_MODEL_2e95f98365e04b04b1323512bff67d33"],"layout":"IPY_MODEL_5e18abd6f7de4f64b5f595322a1fd27c"}},"d4aa3f6acd6549779c5c81d4e4818dcb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b47678ce1dc84c2a9dea9edfd8966f7c","placeholder":"​","style":"IPY_MODEL_c03b6eb041a24e0abb4fb10bec72dca0","value":"Map: 100%"}},"83e05cda0102478f8eec6ebfd2f18cab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d5f8f6f494f4ecabd9f962ae63ba280","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b8153a80b464d508e84fa1e62a2d89f","value":300}},"2e95f98365e04b04b1323512bff67d33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd0d4667c0e4425ead561288139425e3","placeholder":"​","style":"IPY_MODEL_a3a5f7f6649c4ebebcecbfcf2f515824","value":" 300/300 [00:00&lt;00:00, 1144.15 examples/s]"}},"5e18abd6f7de4f64b5f595322a1fd27c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b47678ce1dc84c2a9dea9edfd8966f7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c03b6eb041a24e0abb4fb10bec72dca0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d5f8f6f494f4ecabd9f962ae63ba280":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b8153a80b464d508e84fa1e62a2d89f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd0d4667c0e4425ead561288139425e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3a5f7f6649c4ebebcecbfcf2f515824":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d355fa8214dc4c9da9053aadb8b294a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45e79fd134c64d9d9813943f2e0e29cf","IPY_MODEL_8b40d03085cb44769d6bdb90bf92a69d","IPY_MODEL_cb445220a1a945ed85cf4edbfbae2456"],"layout":"IPY_MODEL_639c940a7a494023bdea60ad15cfbd54"}},"45e79fd134c64d9d9813943f2e0e29cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52fc3747877a4e3c8784b94462284d0d","placeholder":"​","style":"IPY_MODEL_6c06bbbf20d74b95ab78229dc72467df","value":"  1%"}},"8b40d03085cb44769d6bdb90bf92a69d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa056e410c7543e59c7f3b82385d137c","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f37e0d9eb86340bfb7eeee209dbda42a","value":2}},"cb445220a1a945ed85cf4edbfbae2456":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_732c067679304d638654e2edf84d5e76","placeholder":"​","style":"IPY_MODEL_b7ee1349daf84e4a8c4366d8086961d7","value":" 2/300 [00:08&lt;20:11,  4.06s/it]"}},"639c940a7a494023bdea60ad15cfbd54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52fc3747877a4e3c8784b94462284d0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c06bbbf20d74b95ab78229dc72467df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa056e410c7543e59c7f3b82385d137c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f37e0d9eb86340bfb7eeee209dbda42a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"732c067679304d638654e2edf84d5e76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7ee1349daf84e4a8c4366d8086961d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}