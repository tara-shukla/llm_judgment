Model,LLMBar,MT Bench,JudgeBench,Comparison Task,Parameters
gpt2-small,,,,37,"137,000,000"
gpt2-large,,,,42,"812,000,000"
llama-3.2-3b,,,,40,"1,240,000,000"
llama-3.2-1b-it,48.48484848,47.61904762,53.42465753,45,"3,210,000,000"
llama-3.2-3b-it,63.63636364,68.02721088,41.09589041,54,"3,210,000,000"
olmo-7b-it,60.60606061,53.06122449,45.20547945,48,"6,890,000,000"
olmoe-1b-7b-0924-it,68.18181818,49.65986395,58.90410959,48,"6,920,000,000"
olmo-2-0325-32b-it,,72.78911565,,,"32,200,000,000"
flan-t5-small,46.96969697,50.34013605,57.53424658,39,"77,000,000"
flan-t5-large,60.60606061,51.70068027,42.46575342,65,"783,000,000"
flan-t5-xl,66.66666667,64.62585034,41.09589041,70,"2,850,000,000"
qwen-2.5-0.5b-it,53.03030303,46.93877551,49.31506849,52,"494,000,000"
qwen-2.5-1.5b-it,57.57575758,68.02721088,47.94520548,60,"1,540,000,000"
qwen-2.5-3b-it,81.81818182,71.42857143,49.31506849,63,"3,090,000,000"
qwen-2.5-7b-it,84.84848485,72.10884354,52.05479452,65,"7,620,000,000"
qwen-2.5-7b-it-1m,83.33333333,75.51020408,52.05479452,66,"7,620,000,000"
phi-3-mini-4k-it,60.60606061,70.75764657,63.01369863,72,"3,820,000,000"
phi-3.5-mini-it,66.66666667,71.42857143,58.90410959,72,"3,820,000,000"
phi-4-mini-it,71.21212121,57.82312925,61.64383562,70,"3,840,000,000"
phi-3-medium-4k-it,59.09090909,74.14965986,52.05479452,79,"14,000,000,000"
mistral-7b-it-v0.1,46.96969697,51.70068027,57.53424658,65,"7,240,000,000"
mistral-7b-it-v0.3,68.18181818,65.98639456,56.16438356,67,"7,250,000,000"
mistral-8b-it-2410,78.78787879,66.66666667,56.16438356,76,"8,020,000,000"
mistral-nemo-it-2407,75.75757576,65.65876979,54.79452055,77,"12,200,000,000"
gemma-2b,,,,64,"2,510,000,000"
gemma-1.1-2b-it,57.57575758,59.18367347,61.64383562,69,"2,510,000,000"
gemma-2-2b-it,60.60606061,54.42176871,56.16438356,78,"2,610,000,000"